{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6411d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08527a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file_to_string(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "file_path = 'predict.txt'\n",
    "file_contents = load_file_to_string(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee8a0646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computers consist of electronical components.\\niam using windows 10 because i dont like windows 11.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcfb9a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = list(stopwords.words('english'))\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"\\\\n\", \"\")\n",
    "    text = text.replace(\"\\\\\", \"\")\n",
    "    text = text.replace(\"'\", \"\")\n",
    "    pattern = r\"^[a-z]+(-[a-z]+)*.?$\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if  re.match(pattern, token)]\n",
    "    tokens = [x for x in tokens if x not in stop]\n",
    "    \n",
    "    return list(tokens)\n",
    "\n",
    "text_token = tokenize(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a159ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map = {\n",
    "    \"N\": \"n\",\n",
    "    \"V\": \"v\",\n",
    "    \"R\": \"r\",\n",
    "    \"J\": \"a\"\n",
    "}\n",
    "\n",
    "def pos_lemma(tokens):\n",
    "    tags=pos_tag(tokens)\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    w_net_lemma=[]\n",
    "    for token ,tag in tags:\n",
    "        if(tag_map.get(tag[0]) is not None ):\n",
    "            w_net_lemma.append(lemmatizer.lemmatize(token,pos=tag_map[tag[0]]))\n",
    "        else:\n",
    "            w_net_lemma.append(lemmatizer.lemmatize(token,pos='n'))\n",
    "            \n",
    "    return list(w_net_lemma)\n",
    "\n",
    "text_lemma = pos_lemma(text_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e62d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = joblib.load(\"pk1/general_tfidf.joblib\")\n",
    "text_tfidf =  tfidf_vect.transform(text_lemma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7e11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = {\n",
    "    0: 'alt.atheism',\n",
    "    1: 'comp.graphics',\n",
    "    2: 'comp.os.ms-windows.misc',\n",
    "    3: 'comp.sys.ibm.pc.hardware',\n",
    "    4: 'comp.sys.mac.hardware',\n",
    "    5: 'comp.windows.x',\n",
    "    6: 'misc.forsale',\n",
    "    7: 'rec.autos',\n",
    "    8: 'rec.motorcycles',\n",
    "    9: 'rec.sport.baseball',\n",
    "    10: 'rec.sport.hockey',\n",
    "    11: 'sci.crypt',\n",
    "    12: 'sci.electronics',\n",
    "    13: 'sci.med',\n",
    "    14: 'sci.space',\n",
    "    15: 'soc.religion.christian',\n",
    "    16: 'talk.politics.guns',\n",
    "    17: 'talk.politics.mideast',\n",
    "    18: 'talk.politics.misc',\n",
    "    19: 'talk.religion.misc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c55c0ed",
   "metadata": {},
   "source": [
    "<!-- Class is alt.atheism and its number is 0\n",
    "Class is comp.graphics and its number is 1\n",
    "Class is comp.os.ms-windows.misc and its number is 2\n",
    "Class is comp.sys.ibm.pc.hardware and its number is 3\n",
    "Class is comp.sys.mac.hardware and its number is 4\n",
    "Class is comp.windows.x and its number is 5\n",
    "Class is misc.forsale and its number is 6\n",
    "Class is rec.autos and its number is 7\n",
    "Class is rec.motorcycles and its number is 8\n",
    "Class is rec.sport.baseball and its number is 9\n",
    "Class is rec.sport.hockey and its number is 10\n",
    "Class is sci.crypt and its number is 11\n",
    "Class is sci.electronics and its number is 12\n",
    "Class is sci.med and its number is 13\n",
    "Class is sci.space and its number is 14\n",
    "Class is soc.religion.christian and its number is 15\n",
    "Class is talk.politics.guns and its number is 16\n",
    "Class is talk.politics.mideast and its number is 17\n",
    "Class is talk.politics.misc and its number is 18\n",
    "Class is talk.religion.misc and its number is 19 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97610bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 544ms/step\n",
      "Predictions for NN is comp.sys.ibm.pc.hardware\n"
     ]
    }
   ],
   "source": [
    "NN_model = load_model(\"pk1/NN_model.h5\")\n",
    "text_tfidf_reshaped = text_tfidf.toarray()\n",
    "pred = NN_model.predict(text_tfidf_reshaped)\n",
    "pred = pred[0]\n",
    "pred = np.argmax(pred)\n",
    "print(f\"Predictions for NN is {class_dict[pred]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41412dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aho)",
   "language": "python",
   "name": "aho"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
